{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3417f685-35d2-425e-8302-accc8eb6dd3b",
   "metadata": {},
   "source": [
    "# Binned Likelihood fit\n",
    "\n",
    "This is a introduction to Binned Likelihood fit, which applies when the data has been binned, but the statistics is low (otherwise, one would use a ChiSquare fit). The example is inspired by [Covid-19 calculations related to the arrival of the first variant](https://dm.dk/forskerforum/magasinet/2021/343/forskerne-bag-coronamodellerne/), where day 1 is then 1st of December 2020 (first observation of the B.1.1.7 \"British\" Alpha variant).\n",
    "\n",
    "The code is an illustration of the difference between a ChiSquare and a Binned Likelihood fit.\n",
    "\n",
    "The main task is to play around with the amount of samples we are given to fit the progression of the spread of a disease, and see how different methods cope when the data present is low.\n",
    "\n",
    "\n",
    "### Authors: \n",
    "- Malthe Nordentoft (Niels Bohr Institute, malthe.nordentoft@nbi.ku.dk)\n",
    "- Troels C. Petersen (Niels Bohr Institute, petersen@nbi.dk)\n",
    "\n",
    "### Date:    \n",
    "- 21-11-2024 (latest update)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446dd7d-4474-465b-bce9-fa40b2741dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from iminuit import Minuit\n",
    "from iminuit import cost\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719be55b-98f5-416c-adb6-2b6aa7e35caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random   # Random generator\n",
    "r.seed(44)      # Set a random seed (but a fixed one)\n",
    "\n",
    "# Truth values for sampling and disease progression:\n",
    "samples = 1000\n",
    "slope = 0.075\n",
    "thalf = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efc4e3-44af-4877-93db-8ea1b83c17c2",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "In this data set we want to predict how fast a new type of disease will spread in a population, and forcast a time point in the future $t_{1/2}$ where half of the new infections are du to the new variant. We are in the early days of the new disease, thus we only have data from the last month (Ndays = 30). Every day 100 test are conducted, and the number of new variant cases is given. We have good reason to believe that the spread of the diseases grows as a sigmoid function (two competing exponentials), so that is the fitting function.\n",
    "\n",
    "<center>\n",
    "Your mission - and you have no choice but to accept it - is to determine when one should expect $t_{1/2}$.\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c26ce-13dd-4f3f-bcac-346abf8a58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(time, slope, thalf, N):\n",
    "    return N/(1 + np.exp(-slope*(time - thalf)))\n",
    "\n",
    "def generate_data(time):\n",
    "    rates = sigmoid(time, slope, thalf, samples)\n",
    "    gamma = []\n",
    "    for i in range(len(time)):\n",
    "        gamma.append(np.random.poisson(rates[i]))\n",
    "    return np.array(gamma)\n",
    "\n",
    "Ndays = 30\n",
    "time = np.arange(Ndays)\n",
    "data_Npos = generate_data(time)       # Data, consisting of Npositives (with new variant) daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743addba-085f-454e-a088-43c911166159",
   "metadata": {},
   "source": [
    "## Visualising the data\n",
    "\n",
    "The data given by the doctors are given below, as already binned data. As is obvious below, the data is very sparse but it is the best we can do at the current time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f5ea4-bb90-4c09-96d0-ba8c0de4880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (7,5))\n",
    "ax.bar(time, data_Npos)\n",
    "ax.set(xlabel = 'Time Days', ylabel = 'Number of positive test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fee8db-392c-4808-abda-13e8c2419261",
   "metadata": {},
   "source": [
    "## Binned likelihood\n",
    "We define our own Binned likelihood function, to fit the histogram given to us. It is a good assumption that the bincount of a histogram is poisson distributed, thus we compute the likelihood between the measured bin count and the predicted bincount given the rate of positive samples given our sigmoid progression of the diseases. Finally we take the log of the product of the likelihoods, as this is bennefitial when minimizing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cc4e0-048d-4e34-a8ad-25778c2ade15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinnedLH(slope, thalf):\n",
    "    rates = sigmoid(time, slope, thalf, samples) \n",
    "    return np.sum(-2*np.log(stats.poisson.pmf(data_Npos, rates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298c12a-c66d-4971-91a5-c93f4b4ccf87",
   "metadata": {},
   "source": [
    "## Fitting the data\n",
    "We make an educated guess on some fitting parameter for the sigmoid function, and thereafter fit with both a Binned Likelihood method and a Chi2 method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce084dfa-d419-45fe-bbdd-c3f1b1ed8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_guess = 0.15\n",
    "thalf_guess = 50\n",
    "\n",
    "mfit = Minuit(BinnedLH, slope = slope_guess, thalf = thalf_guess)\n",
    "mfit.errordef = 0.5\n",
    "mfit.migrad()\n",
    "\n",
    "mfit.errordef = 1.0\n",
    "c = cost.LeastSquares(time[data_Npos>0], data_Npos[data_Npos > 0], np.sqrt(data_Npos[data_Npos>0]), sigmoid)\n",
    "mfit_chi2 = Minuit(c, slope = slope_guess, thalf = thalf_guess, N = samples)\n",
    "mfit_chi2.fixed[\"N\"] = samples   # Fixed as we always take same number of samples every day, thus it is not a fitting parameter\n",
    "mfit_chi2.migrad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b75a1e-d063-4334-a460-8b8be68bbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_time = np.arange(120)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (10, 6))\n",
    "ax.set_xlim(0,120)\n",
    "ax.bar(time, data_Npos)\n",
    "ax.set(xlabel = 'Time Days', ylabel = 'Number of positive test')\n",
    "ax.plot(future_time, sigmoid(future_time, slope, thalf,    samples), label = \"Actual progression of the disease\" )\n",
    "ax.plot(future_time, sigmoid(future_time, *mfit.values[:], samples), label = 'Binned Likelihood fit')\n",
    "ax.plot(future_time, sigmoid(future_time, *mfit_chi2.values[:]), label = 'Chi2 fit')\n",
    "ax.vlines(thalf,               0, samples/2, label = 'Actual $t_{half}$', ls = '--')\n",
    "ax.vlines(mfit.values[1],      0, samples/2, label = 'Binned likelihood $t_{half}$', ls = '--', color = 'tab:orange')\n",
    "ax.vlines(mfit_chi2.values[1], 0, samples/2, label = 'Chi2 $t_{half}$', ls = '--', color = 'tab:green')\n",
    "\n",
    "ax.fill_between([mfit.values[1] - mfit.errors[1], mfit.values[1] + mfit.errors[1]], [0, 0], [sigmoid(mfit.values[1] - mfit.errors[1],\n",
    "                                *mfit.values, samples), sigmoid(mfit.values[1] + mfit.errors[1], *mfit.values, samples)], color = 'tab:orange', alpha = 0.5)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3786fdb-79ca-4b08-a6cb-a2e712047f50",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. Alter the number of samples taken a day from 1000 to say 200, 100, and 50, and see the effect of statistics.\n",
    "\n",
    "_Example Answer 1:_ As we increase the number of samples we also decrease the uncertainty on the measurements, which makes the fit way better. As we decrease the number of measureements the uncertainty increases alot, and for some measurements even end up as zero, making it much harder for the chi2 method to create a good fit. This is here where the binnedLH fit shines, and where it is preferable to use it over a Chi2 method. One could also try to use a UnbinnedLH, but this would entail trying to \"unbin\" the data which complicates thing unnecessarily. \n",
    "\n",
    "***\n",
    "\n",
    "2. Use samples=100, and alter the amount of days that we have tested for the diseases for, to investigate how early the binned likelihood (and the ChiSquare) fit can reasonably predict the outcome.\n",
    "\n",
    "_Example Answer 2:_ Even at low values like 15 days we get a good fit almost always. However, now the ChiSquare fit certaintly has its problems, and occationally gets the answer completely wrong.\n",
    "\n",
    "***\n",
    "\n",
    "### (Semi) Advanced question\n",
    "3. Right now we assume that the diseases starts the day we start testing for it. Ususally we are not that great at predicting the onset of a disease. Alter the script in a way so that the $t_{1/2}$ prediction is the number of days into the future (i.e. after day 30)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting is an Art!\n",
    "\n",
    "Python macro for testing which fitting procedure is likely to give the \"best\" results.\n",
    "\n",
    "In this case, we consider **a function with x-values far from zero** leading to extremely high correlations.\n",
    "Mixed with bad starting parameters, the fit fails.\n",
    "\n",
    "### Authors:\n",
    "- Troels Petersen ([email](mailto:petersen@nbi.dk))\n",
    "\n",
    "### Last update:\n",
    "- 28th of December 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from iminuit import Minuit, cost\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random\n",
    "r.seed(40)\n",
    "SavePlots = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE: Fit with x-values in a small range far from zero:\n",
    "\n",
    "The initial fitting function is the following:\n",
    "\n",
    "* $f(x) = ax + b$\n",
    "\n",
    "If the x-values are far from zero (e.g. the year we are in), then any change in $a$ gives a major change in $b$, and the two gets very correlated. However, if the mean $x$-value (or some value close to it) is subtracted from $a$ in the function, then this is avoided, as $b$ is now the $y$ value at the middle of this point, which is not subject to much change.\n",
    "\n",
    "* $f(x) = a(x - \\bar{x}) + b$\n",
    "\n",
    "The linear function is a particularly simple example, which can be solved numerically. In the below example, we consider the **exponential function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant range:\n",
    "xmin = 2020\n",
    "xmax = 2021\n",
    "Npoints = 13\n",
    "\n",
    "# Function parameters:\n",
    "a = 110.0\n",
    "b = 0.005\n",
    "c = -100.0\n",
    "sigmay = 0.5\n",
    "\n",
    "# Generating (thus known) data:\n",
    "x = np.linspace(xmin, xmax, Npoints)\n",
    "y = a*np.exp(b*(x-2020)) + c + r.normal(0.0, sigmay, len(x))\n",
    "sy = sigmay * np.ones(Npoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_bad(x, a, b, c) :\n",
    "    # return a*x + b\n",
    "    return a*np.exp(b*x) + c\n",
    "\n",
    "def func_good(x, a, b, c) :\n",
    "    # return a*(x-2015) + b\n",
    "    return a*np.exp(b*(x-2020)) + c\n",
    "\n",
    "cfit = cost.LeastSquares(x, y, sy, func_bad)\n",
    "mfit = Minuit(cfit, a=0.0, b=0.0, c=0.0)\n",
    "mfit.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit = np.linspace(xmin, xmax, 1000)\n",
    "y_fit = func_good(x_fit, *mfit.values[:])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plot_data = ax.errorbar(x, y, sy, fmt='.', linewidth=2, color='blue', label=\"Data\")\n",
    "ax.plot(x_fit, y_fit, '-', color='red', linewidth=2, label='ChiSquare fit')\n",
    "ax.set(xlabel='x (year)', ylabel='y')\n",
    "ax.legend(loc='upper left', fontsize=20)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "Consider the case and argue/discuss which fitting procedure should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning points:\n",
    "\n",
    "This exercise in \"fitting tricks\" should teach you that:\n",
    "1. __Good starting values is paramount!__ (Almost all fits fail with poor starting values).\n",
    "2. The form of the fitting function is also important.<br>\n",
    "   a. Ensure that the x-values do not represent some small range far from 0.<br>\n",
    "   b. Ensure that you give the fitting function enough freedom to fit the data.<br>\n",
    "   c. Conversely, try to curb the number of parameters, if there are arguments for doing so (calibration peaks).<br>\n",
    "   d. Make sure that you've normalised your fitting PDFs, to avoid correlations between normalisation and parameters.\n",
    "3. If a fit continues to fail, try simply to draw the function and starting values on top of the data. Often, they don't match well (general advice, not just in this exercise)."
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
